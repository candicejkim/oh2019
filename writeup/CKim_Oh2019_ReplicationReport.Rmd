---
title: "Replication of Revealing Hidden Gender Biases in Competence Impressions of Faces by Oh et al. (2019, Psychological Science)"
author: "Candice Kim (candicekim@stanford.edu)"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: false
---

##Introduction

For this project, I seek to replicate the findings of Experiment 3 of the study conducted by Oh et al. (2019) titled "Revealing Hidden Gender Biases in Competence Impressions of Faces." This study overall sought to identify the components of competence stereotype using data-driven computational models. For Experiment 3, the authors tested whether gender-related facial cues were used to judge competence. They presented participants with faces that varied on perceived competence and asked them to categorize them as male or female. THe authors found that faces manipulated to appear competent but not attractive were more likely to be classified as male, suggesting that gender bias influences competence impressions. I am interested in replicating this study, and particularly this experiment, because of my research interest in gender equity in medicine. Prior research has shown that leadership in academic medicine and specific medical specialties such as surgery are overwhelmingly male dominated. Better understanding the role of gender bias on critical factors such as perceived competence, which influences hiring decisions, promotions, and program acceptance rates, can provide insight on current gender gaps in medicine.

This reproduction study will be conducted using Amazon Mechanical Turk (MTurk) to recruit participants. The original study included 30 participants, accounting for test-retest reliability of greater than 0. The authors used face images computationally manipulated using both the competence model and the difference model to generate a pool of 350 face-image stimuli (2 models x 25 identities x 7 manipulation levels). For each face-image stimulus, participants were asked to make a forced choice of male or female. Two version of the study were created: (1) 88 competence-model faces + 87 difference-model faces and (2) 87 competence-model faces + 88 difference-model faces. Each version included unique image stimuli with no overlap of images. The 175 images for each version were presented to the participant, who was then asked to respond to the question "What is the gender of this person?" with two options male or female. To assess intrarater reliability, 25 trials from the first 175 trials were randomly repeated to bring the total of trials to 200 for each participant. Responses of participants who had a test-retest reliability less than or equal to 0 were excluded. I believe the major challenge to reproducing this study will be generating the face-image stimuli since I am not familiar with the program the authors used to create the images. Perhaps I can use the same images the authors used in their study, but I am not sure if this would be considered sufficient for this replication project. Additionally, I have not used Amazon MTurk before and have limited coding experience. As such, I am not sure how difficult it will be to create the interface needed for the 200 trials (the last 25 of which are random repeats from the first 175) and whether my coding experience will be sufficient. One potential concern I had was being able to recruit enough participants on MTurk. However, for this study, the authors included 30 participants, which seems like an attainable number.

[Repository](https://github.com/candicejkim/oh2019/)

[Original Paper](https://github.com/candicejkim/oh2019/blob/master/original_paper/Oh_etal_2019.pdf)

##Methods

###Power Analysis

The original effect size was eta-squared = 0.88 (p < .001) with F = 464.32 for a repeated measures ANOVA test. The authors' power anaysis was conducted using G*Power 3.1.9, which calculated that a "sample size of at least 26 participants would afford 95% power to detect a small to medium effect (f = .25) of the main effects of manipulation level and model type, as well as the interaction between the two."

Original effect size, power analysis for samples to achieve 80%, 90%, 95% power to detect that effect size. Considerations of feasibility for selecting planned sample size.

[I will be going to office hours this week for help with using G*Power to complete this section.]

###Planned Sample

The original study included 30 participants with an intrarater reliability score greater than 0 (see procedure section for more details). The same sample size will be planned for this replication report. The original study ended up including 31 participants total because 1 participant had an intrarater reliability score of 0. For this replication study, enough participants will be recruited - and the study will remain open - until 30 participants with an intrarater reliability score greater than 0 participate. The original study did not specify known demographics or preselection rules. For this replication study, the typical MTurk qualifications (located in US, HIT approval rate greater than 97%, and greater than 5000 number of HITs approved) will be used.

###Materials

"We used both the face images manipulated by the competence model and the face images manipulated by the difference model. This created a combined pool of 350 face-image stimuli (2 models × 25 identities × 7 manipulation levels)." The same materials from the original study, quoted above, will be followed for this replication study.

[Paradigm](https://stanforduniversity.qualtrics.com/jfe/form/SV_2mhyDSzzzr2q2Il)

###Procedure	

"Participants were asked to make a forced choice of perceived gender for each face. All participants were exposed to faces from both the competence and difference models. Two versions of the study with the same length were created: Half of the participants were presented with 88 competence-model faces and 87 difference-model faces, whereas the other half were presented with 87 competence-model faces and 88 difference-model faces. There was no overlap in the face images between the two versions of the study.

The 175 chosen stimuli were presented in random order to each participant. For each stimulus, the question asked was “What is the gender of this person?” presented with two options: male or female. Left and right arrow keys were used to indicate one or the other gender, and the gender–key mapping was counterbalanced. Before the experiment began, each participant was told to rely on gut instinct, not to spend too much time on each face, and that there were no right or wrong answers. Participants were given unlimited time.

To assess intrarater reliability, we added 25 repeated trials randomly chosen from the first 175 trials in each study, bringing the total number of trials to 200. As we did in the previous experiments, we excluded the responses of participants with test-retest reliability less than or equal to 0: 1 participant. We recruited an additional participant so that we had 30 participants with test-retest reliability greater than 0." The same procedure from the original study, quoted above, will be followed for this replication study.

###Analysis Plan

In this study, participants are asking to assign binary gender - male or female - to computer-generated face images that have been manipulated either according to the competence model or the difference model. Participants are excluded if their intrarater reliability score is 0 (see procedure section above).

The first analysis that will be done is conducting a t-test to determine whether the proportion of "male" responss to all faces averaged across participants was significantly different from 0.5.

The second analysis will involve plotting the mean proportion of "male" responses as a function of the level of the difference-model manipulation and the competence-model manipulation. The graph will be fitted with a sigmoid function for the response averaged across participants with error bars denoting standard errors.

The third analysis will be conducting a "7 (manipulation level) × 2 (model type) repeated measures analysis of variance on the proportion of “male” responses for each face" to "test whether the perceived gender of faces tracked the model manipulations."

The authors also conducted 7 (manipulation level) × 2 (model type) repeated measure ANOVA tests. The most relevant test for replication was the repeated measure ANOVA testing whether faces that were manipulated to look more competent, regardless of model type, would be more likely to be categorized as male.

**Clarify key analysis of interest here**  The key analysis of interest is the second analysis described above in which the mean proportion of "male" responses will be plotted as a function of the difference and competence-model manipulations. A sigmoid function will be fitted to the resulting plot with error bars indicating standard errors. There will be a single plot generated with the responses averaged across participants. This graph will essentially be a replication of the original paper's Figure 4, which was the key figure for the experiment being replicated.

###Differences from Original Study

The procedure, analysis plan, and setting of MTurk will exactly follow the original study. A difference, however, will likely be the participants' demographics. The original study did not specify any particular restrictions for excluding MTurk workers from participating. As such, this replication study will follow the standard MTurk qualifications (located in the US, HIT approval rate greater than 97%, and greater than 5000 HITs approved). Other than these qualifications, the study will be open to any MTurk workers who agree to participate. In the original study, "thirty-one MTurk workers (22 men, 9 women; age: M = 36.32 years, range = 20–58) participated." One of these MTurk workers was excluded from analysis because their intrarater reliability score was equal to 0 (refer to procedure section). When recruiting participants for this replication report, the same demographics in terms of age range and gender breakdown may not be the same. As the original study cited, prior research has shown that "people evaluate men as more competent and more confident than women, on average" and that the "association between men and competence, confidence, and semanitically similar traits (e.g. independence, inventiveness) are held across diverse cultures." As such, although  the  demographics of MTurk workers will likely not be precisely the same for this replication study, it is anticipated that this difference will not drastically influence the outcomes of the study.

### Methods Addendum (Post Data Collection)

You can comment this section out prior to final report with data collection.

#### Actual Sample
  Sample size, demographics, data exclusions based on rules spelled out in analysis plan

#### Differences from pre-data collection methods plan
  Any differences from what was described as the original plan, or “none”.


##Results

[I am still gathering pilot data. I plan on doing so tomorrow (10/19). Since I do not have data yet, I have not coded the analysis plan. But I will plan on coding this analysis before my midterm presentation on Friday (10/23), so I can show preliminary analyses.]

### Data preparation

Data preparation following the analysis plan.
	
```{r include=F}
###Data Preparation

####Load Relevant Libraries and Functions

####Import data

#### Data exclusion / filtering

#### Prepare data for analysis - create columns etc.
```

### Confirmatory analysis

The analyses as specified in the analysis plan.  

*Side-by-side graph with original graph is ideal here*

###Exploratory analyses

Any follow-up analyses desired (not required).  

## Discussion

### Summary of Replication Attempt

Open the discussion section with a paragraph summarizing the primary result from the confirmatory analysis and the assessment of whether it replicated, partially replicated, or failed to replicate the original result.  

### Commentary

Add open-ended commentary (if any) reflecting (a) insights from follow-up exploratory analysis, (b) assessment of the meaning of the replication (or not) - e.g., for a failure to replicate, are the differences between original and present study ones that definitely, plausibly, or are unlikely to have been moderators of the result, and (c) discussion of any objections or challenges raised by the current and original authors about the replication attempt.  None of these need to be long.
